{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available!\")\n",
        "else:\n",
        "    print(\"GPU NOT available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULg6Bimai_Vi",
        "outputId": "7e7297dc-e5a8-4ff4-8fe3-9bc861ffd97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "kc5E6KpR8iIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74434af-1a76-4a3f-d859-5f8472674167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "LmLW0JGYWvLK",
        "outputId": "72a68b9a-afd2-47af-99a2-723c1a3c30af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1bde2027-ed57-45b5-8adf-b2ff83a8cbfe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1bde2027-ed57-45b5-8adf-b2ff83a8cbfe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# ÙÙƒ Ø§Ù„Ø¶ØºØ· Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„ ÙÙŠ Ù…Ø¬Ù„Ø¯ \"new\"\n",
        "with zipfile.ZipFile(\"/content/new.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"new\")\n",
        "\n",
        "# ÙÙƒ Ø§Ù„Ø¶ØºØ· Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ ÙÙŠ Ù…Ø¬Ù„Ø¯ \"test\"\n",
        "with zipfile.ZipFile(\"/content/test.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"test\")\n",
        "\n",
        "# Ø·Ø¨Ø§Ø¹Ø© Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯ÙŠÙ†\n",
        "print(\"new contents:\", os.listdir(\"new\"))\n",
        "print(\"test contents:\", os.listdir(\"test\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRnDYxf4W0sJ",
        "outputId": "5debec26-f4da-40e3-e066-c2376412f434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new contents: ['new']\n",
            "test contents: ['test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"new\"\n",
        "path2 = \"test\"\n",
        "\n",
        "# Ø·Ø¨Ø§Ø¹Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·\n",
        "print(f\"{path1} contents:\", os.listdir(path1))\n",
        "print(f\"{path2} contents:\", os.listdir(path2))"
      ],
      "metadata": {
        "id": "WG2i0s-JXQ8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2dd94a-587c-4d34-c660-9d3f6745c2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new contents: ['new']\n",
            "test contents: ['test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k12QNcpTlP4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_data_paths():\n",
        "    # Your existing directories\n",
        "    test_dir = \"/content/organized_dataset/test\"\n",
        "    val_dir = \"/content/organized_dataset/validation\"\n",
        "    train_dir = \"/content/organized_dataset/train\"\n",
        "\n",
        "    return train_dir, val_dir, test_dir\n",
        "\n",
        "# Setup paths for your existing structure\n",
        "train_dir, val_dir, test_dir = setup_data_paths()"
      ],
      "metadata": {
        "id": "x1vrAuGoHE_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if9t5S4uTlP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945fef57-ea48-45ad-bf56-dd23a70d6bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking data availability in your folders...\n",
            "âŒ Directory not found: /content/organized_dataset/train/brain_glioma\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "âŒ Directory not found: /content/organized_dataset/train/brain_menin\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "âŒ Directory not found: /content/organized_dataset/validation/brain_glioma\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "âŒ Directory not found: /content/organized_dataset/validation/brain_menin\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "âŒ Directory not found: /content/organized_dataset/test/brain_glioma\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "âŒ Directory not found: /content/organized_dataset/test/brain_menin\n",
            "   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\n",
            "\n",
            "Total images found: 0\n",
            "Expected total: 2094\n",
            "âš ï¸  No images found. Please check your folder structure.\n"
          ]
        }
      ],
      "source": [
        "def check_data_availability():\n",
        "    \"\"\"Check if data is available in your existing directories\"\"\"\n",
        "    print(\"\\nChecking data availability in your folders...\")\n",
        "\n",
        "    dirs_to_check = [\n",
        "        os.path.join(train_dir, \"brain_glioma\"),      # new/brain_glioma\n",
        "        os.path.join(train_dir, \"brain_menin\"),  # new/brain_menin\n",
        "        os.path.join(val_dir, \"brain_glioma\"),        # val/brain_glioma\n",
        "        os.path.join(val_dir, \"brain_menin\"),    # val/brain_menin\n",
        "        os.path.join(test_dir, \"brain_glioma\"),       # test/brain_glioma\n",
        "        os.path.join(test_dir, \"brain_menin\")    # test/brain_menin\n",
        "    ]\n",
        "\n",
        "    expected_counts = [1300, 61, 400, 18, 300, 15]  # Expected image counts\n",
        "    total_images = 0\n",
        "\n",
        "    for i, dir_path in enumerate(dirs_to_check):\n",
        "        if os.path.exists(dir_path):\n",
        "            num_files = len([f for f in os.listdir(dir_path)\n",
        "                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))])\n",
        "            expected = expected_counts[i]\n",
        "            status = \"âœ…\" if num_files > 0 else \"âš ï¸\"\n",
        "            print(f\"{status} {dir_path}: {num_files} images (expected: {expected})\")\n",
        "            total_images += num_files\n",
        "\n",
        "            if num_files == 0:\n",
        "                print(f\"   âŒ WARNING: No images found in {dir_path}\")\n",
        "        else:\n",
        "            print(f\"âŒ Directory not found: {dir_path}\")\n",
        "            print(f\"   ğŸ’¡ Make sure you have subfolders: brain_glioma and brain_meningioma\")\n",
        "\n",
        "    print(f\"\\nTotal images found: {total_images}\")\n",
        "    print(f\"Expected total: {sum(expected_counts)}\")\n",
        "\n",
        "    if total_images > 0:\n",
        "        print(\"âœ… Data is available! Ready to proceed.\")\n",
        "    else:\n",
        "        print(\"âš ï¸  No images found. Please check your folder structure.\")\n",
        "\n",
        "    return total_images > 0\n",
        "\n",
        "# Check if data is available\n",
        "data_available = check_data_availability()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(img_height=224, img_width=224, num_classes=3):\n",
        "    \"\"\"Create lightweight transfer learning model using MobileNetV2\"\"\"\n",
        "    # Load pre-trained MobileNetV2 (much smaller than ResNet50)\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(img_height, img_width, 3),\n",
        "        alpha=1.0  # Width multiplier, use 0.75 or 0.5 for even smaller model\n",
        "    )\n",
        "\n",
        "    # Freeze base model layers initially\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add lightweight custom classification head\n",
        "    inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(128, activation='relu')(x)  # Smaller dense layer\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)   # Even smaller\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    print(f\"Model created with {model.count_params():,} parameters\")\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OivosKLOelq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "90c420e3-7176-442b-9cbb-8e75e78f62b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created with 2,435,523 parameters\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚         \u001b[38;5;34m5,120\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m163,968\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,435,523\u001b[0m (9.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435,523</span> (9.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m174,979\u001b[0m (683.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,979</span> (683.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,260,544\u001b[0m (8.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,260,544</span> (8.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_generators(batch_size=16):\n",
        "    \"\"\"Prepare data generators with augmentation\"\"\"\n",
        "\n",
        "    # Training data generator with augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.15,\n",
        "        brightness_range=[0.9, 1.1],\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Validation and test data generators (only rescaling)\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_test_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "# Only prepare generators if data is available\n",
        "if data_available:\n",
        "    train_gen, val_gen, test_gen = prepare_data_generators(batch_size=16)\n",
        "    print(\"Data generators created successfully!\")\n",
        "    print(f\"Training samples: {train_gen.samples}\")\n",
        "    print(f\"Validation samples: {val_gen.samples}\")\n",
        "    print(f\"Test samples: {test_gen.samples}\")\n",
        "    print(f\"Class indices: {train_gen.class_indices}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Data not available. Please place images in the folders first.\")"
      ],
      "metadata": {
        "id": "OS9poqDkJI2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0aad8e7-254c-47da-fb16-f89b01909517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Data not available. Please place images in the folders first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights():\n",
        "    \"\"\"Calculate class weights for imbalanced dataset\"\"\"\n",
        "    # Based on your distribution\n",
        "    total_glioma = 1300 + 400 + 300  # 2000\n",
        "    total_menin = 61 + 18 + 15   # 94\n",
        "    total_samples = total_glioma + total_menin\n",
        "\n",
        "    weight_glioma = total_samples / (2 * total_glioma)\n",
        "    weight_menin = total_samples / (2 * total_menin)\n",
        "\n",
        "    class_weights = {0: weight_glioma, 1: weight_menin}\n",
        "    print(f\"Class weights calculated:\")\n",
        "    print(f\"  - Glioma (class 0): {weight_glioma:.3f}\")\n",
        "    print(f\"  - Menin (class 1): {weight_menin:.3f}\")\n",
        "    return class_weights\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = calculate_class_weights()"
      ],
      "metadata": {
        "id": "DCN-ngZbJgUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d17546-6420-41a2-ac2e-88357b4d1d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights calculated:\n",
            "  - Glioma (class 0): 0.523\n",
            "  - Menin (class 1): 11.138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks():\n",
        "    \"\"\"Define training callbacks\"\"\"\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=8,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=4,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    return callbacks\n",
        "\n",
        "# Setup callbacks\n",
        "callbacks = get_callbacks()\n",
        "print(\"Training callbacks configured:\")\n",
        "print(\"- Early stopping (patience=8)\")\n",
        "print(\"- Learning rate reduction (patience=4)\")"
      ],
      "metadata": {
        "id": "SPQig7djJyUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761ed633-0ea7-4130-bcbe-bf516998e4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training callbacks configured:\n",
            "- Early stopping (patience=8)\n",
            "- Learning rate reduction (patience=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if data_available:\n",
        "    print(\"Starting Phase 1: Training with frozen base model...\")\n",
        "\n",
        "    # Initial training with frozen base\n",
        "    history_phase1 = model.fit(\n",
        "        train_gen,\n",
        "        epochs=15,\n",
        "        validation_data=val_gen,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"Phase 1 completed!\")\n",
        "else:\n",
        "    print(\"âš ï¸ Skipping training - data not available\")"
      ],
      "metadata": {
        "id": "FXiM3wYuhqIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cf14eb-761a-4e59-d136-6a85a70d8156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Skipping training - data not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if data_available:\n",
        "    print(\"Starting Phase 2: Fine-tuning...\")\n",
        "\n",
        "    # Unfreeze last layers for fine-tuning\n",
        "    base_model = model.layers[1]\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Freeze earlier layers, only train last 20 layers\n",
        "    for layer in base_model.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Use lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    # Continue training\n",
        "    history_phase2 = model.fit(\n",
        "        train_gen,\n",
        "        epochs=15,\n",
        "        validation_data=val_gen,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Combine histories\n",
        "    history = {\n",
        "        'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
        "        'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
        "        'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
        "        'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
        "        'precision': history_phase1.history['precision'] + history_phase2.history['precision'],\n",
        "        'val_precision': history_phase1.history['val_precision'] + history_phase2.history['val_precision'],\n",
        "        'recall': history_phase1.history['recall'] + history_phase2.history['recall'],\n",
        "        'val_recall': history_phase1.history['val_recall'] + history_phase2.history['val_recall']\n",
        "    }\n",
        "\n",
        "    print(\"Phase 2 completed! Training finished.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Skipping fine-tuning - data not available\")"
      ],
      "metadata": {
        "id": "mwQBSuNUBo2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0, 0].plot(history['accuracy'], label='Training', color='blue')\n",
        "    axes[0, 0].plot(history['val_accuracy'], label='Validation', color='red')\n",
        "    axes[0, 0].set_title('Model Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 1].plot(history['loss'], label='Training', color='blue')\n",
        "    axes[0, 1].plot(history['val_loss'], label='Validation', color='red')\n",
        "    axes[0, 1].set_title('Model Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision\n",
        "    axes[1, 0].plot(history['precision'], label='Training', color='blue')\n",
        "    axes[1, 0].plot(history['val_precision'], label='Validation', color='red')\n",
        "    axes[1, 0].set_title('Model Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Recall\n",
        "    axes[1, 1].plot(history['recall'], label='Training', color='blue')\n",
        "    axes[1, 1].plot(history['val_recall'], label='Validation', color='red')\n",
        "    axes[1, 1].set_title('Model Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot training history if available\n",
        "if data_available and 'history' in locals():\n",
        "    plot_training_history(history)\n",
        "else:\n",
        "    print(\"âš ï¸ Training history not available - train the model first\")"
      ],
      "metadata": {
        "id": "etfSkiP0LBes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_generator):\n",
        "    \"\"\"Evaluate model on test set and plot confusion matrix\"\"\"\n",
        "    # Predict class probabilities\n",
        "    predictions = model.predict(test_generator)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = test_generator.classes\n",
        "\n",
        "    # Get class names from generator\n",
        "    class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Safety check for mismatch between predicted classes and class names\n",
        "    unique_classes = np.unique(true_classes)\n",
        "    if len(class_names) != len(unique_classes):\n",
        "        print(f\"âš ï¸ Mismatch detected:\")\n",
        "        print(f\" - test_generator.class_indices has {len(class_names)} classes: {class_names}\")\n",
        "        print(f\" - test set has {len(unique_classes)} classes: {unique_classes.tolist()}\")\n",
        "        print(\"â„¹ï¸ Adjusting class_names to match the true classes in test set...\")\n",
        "        class_names = class_names[:len(unique_classes)]\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nğŸ“‹ Classification Report:\")\n",
        "    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(true_classes, predicted_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluate overall metrics\n",
        "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
        "    print(f\"\\nâœ… Test Set Evaluation:\")\n",
        "    print(f\"Loss     : {test_loss:.4f}\")\n",
        "    print(f\"Accuracy : {test_accuracy:.4f}\")\n",
        "    print(f\"Precision: {test_precision:.4f}\")\n",
        "    print(f\"Recall   : {test_recall:.4f}\")\n",
        "\n",
        "    # F1 Score\n",
        "    if test_precision + test_recall > 0:\n",
        "        f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
        "    else:\n",
        "        f1_score = 0.0\n",
        "    print(f\"F1-Score : {f1_score:.4f}\")"
      ],
      "metadata": {
        "id": "NAe-d-B-LPwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if data_available and 'test_gen' in locals():\n",
        "    evaluate_model(model, test_gen)\n",
        "else:\n",
        "    print(\"âš ï¸ Cannot evaluate - data not available or model not trained\")"
      ],
      "metadata": {
        "id": "l4toKcDNNYZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"brain_tumor_model_final.h5\")\n",
        "print(\"âœ… Model saved as 'brain_tumor_model_final.h5'\")"
      ],
      "metadata": {
        "id": "w1ryGYokOHJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick overfitting check\n",
        "final_train_acc = history['accuracy'][-1]\n",
        "final_val_acc = history['val_accuracy'][-1]\n",
        "gap = final_train_acc - final_val_acc\n",
        "\n",
        "print(f\"Final Train Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Val Accuracy:   {final_val_acc:.4f}\")\n",
        "print(f\"Accuracy Gap:         {gap:.4f}\")\n",
        "\n",
        "if gap > 0.1:\n",
        "    print(\"âš ï¸ Possible overfitting detected.\")\n",
        "else:\n",
        "    print(\"âœ… No strong sign of overfitting.\")"
      ],
      "metadata": {
        "id": "kCM3DC8nO8Ys"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}